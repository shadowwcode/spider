# -*- coding: UTF-8 -*-
# çˆ¬å–ç™¾åº¦è´´å§
# æ‰¾åˆ°æ¯ä¸€ç¯‡å¸–å­çš„ æ ‡é¢˜ã€å‘å¸–äººã€æ—¥æœŸã€æ¥¼å±‚ã€ä»¥åŠè·³è½¬é“¾æ¥
# å°†ç»“æœä¿å­˜åˆ°æ–‡æœ¬

# ç¬¬ä¸€é¡µ
# url = 'http://tieba.baidu.com/f?kw=%E6%9D%83%E5%88%A9%E7%9A%84%E6%B8%B8%E6%88%8F%E7%AC%AC%E4%B8%83%E5%AD%A3&ie=utf-8&pn=0'
# ç¬¬äºŒé¡µ
# url = 'http://tieba.baidu.com/f?kw=%E6%9D%83%E5%88%A9%E7%9A%84%E6%B8%B8%E6%88%8F%E7%AC%AC%E4%B8%83%E5%AD%A3&ie=utf-8&pn=50'
# ç¬¬ä¸‰é¡µ
# url = 'http://tieba.baidu.com/f?kw=%E6%9D%83%E5%88%A9%E7%9A%84%E6%B8%B8%E6%88%8F%E7%AC%AC%E4%B8%83%E5%AD%A3&ie=utf-8&pn=100'
# å‘ç°é¡µæ•°å°±æ˜¯ pn = 50 * (n-1) ä¾¿äºæˆ‘ä»¬æ‹¼æ¥ url

# é€šè¿‡åˆ†ææ¯ä¸ªå¸–å­éƒ½åŒ…å«åœ¨ä¸€ä¸ª  <li class=" j_thread_list clearfix">ä¸­
# å¸–å­é“¾æ¥æ ‡é¢˜ <a href="/p/5328874747" title="æƒåˆ©çš„æ¸¸æˆ1-7å®Œæ•´ç‰ˆï¼ï¼ï¼" target="_blank" class="j_th_tit ">æƒåˆ©çš„æ¸¸æˆ1-7å®Œæ•´ç‰ˆï¼ï¼ï¼</a>
# ä½œè€… <span class="tb_icon_author no_icon_author" title="ä¸»é¢˜ä½œè€…: â˜æ…§ğŸ’–æ…§â˜œ" data-field="{"user_id":2551342822}">
# å›å¸–æ•°é‡ <div class="col2_left j_threadlist_li_left">
# <span class="threadlist_rep_num center_text" title="å›å¤">19</span>
# </div>
# æ—¶é—´: <span class="pull-right is_show_create_time" title="åˆ›å»ºæ—¶é—´">9-18</span>



import requests
from bs4 import BeautifulSoup
import time
import sys
import MySQLdb


def get_html(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        # æˆ‘ä»¬å·²ç»çŸ¥é“ç™¾åº¦è´´å§çš„ ç¼–ç æ˜¯ utf8 æ‰‹åŠ¨è®¾ç½®
        r.encoding = 'utf8'
        return r.text
    except:
        return 'Error'


def get_content(url):
    """åˆ†æç½‘é¡µæ–‡ä»¶ï¼Œæ•´ç†ä¿¡æ¯ï¼Œ ä¿å­˜åœ¨åˆ—è¡¨å˜é‡ä¸­"""
    # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥ä¿å­˜æ‰€æœ‰å¸–å­çš„ä¿¡æ¯
    comments = []
    # è·å–æºæ–‡ä»¶
    html = get_html(url)
    soup = BeautifulSoup(html, 'lxml')

    # æ‰¾åˆ°æ‰€æœ‰å¸–å­ li æ ‡ç­¾
    liTags =soup.find_all('li', attrs={'class': ' j_thread_list clearfix'})

    # éå†æ‰¾åˆ°æˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯
    for li in liTags:
        # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ–‡æœ¬ä¿¡æ¯
        comment = {}
        # é˜²æ­¢çˆ¬è™«æ‰¾ä¸åˆ°ä¿¡æ¯è€Œåœæ­¢
        try:
            comment['title'] = li.find('a', attrs={'class': 'j_th_tit '}).text.strip()
            comment['link'] = 'http://tieba.baidu.com/' + \
                li.find('a', attrs={'class': 'j_th_tit '})['href']
            comment['name'] = li.find('span', attrs={'class': 'tb_icon_author no_icon_author'}).text.strip()
            comment['time'] = li.find('span', attrs={'class': 'pull-right is_show_create_time'}).text.strip()
            comment['replyNum'] = li.find('span', attrs={'class': 'threadlist_rep_num center_text'}).text.strip()
            comments.append(comment)
        except:
            print('something is wrong')
    return comments


def Out2File(dict):
    # """ä¿å­˜åˆ°å½“å‰ç›®å½•çš„ TTbt.txt æ–‡ä»¶ä¸­"""
    # with open('TTbt.txt', 'a+') as f:
    #     for comment in dict:
    #         f.write('Title: {} \t Link: {} \t Author: {} \t Time: {} \t ReplyNum: {} \t'.format(
    #             comment['title'], comment['link'], comment['name'], comment['time'], comment['replyNum']
    #         ))
    print('å½“å‰é¡µé¢çˆ¬å–å®Œæˆ')


class SaveText(object):
    def __init__(self, conn):
        self.conn = conn

    def Save2mysql(self, dict):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        cursor = self.conn.cursor()
        for comment in dict:
            print(comment['title'], comment['name'], comment['time'], comment['link'], comment['replyNum'])
            try:
                sql = 'insert into posts(title, author, time, link, reply) values(%s, %s, %s, %s, %s)' % \
                      (comment['title'], comment['name'], comment['time'], comment['link'], comment['replyNum'])
                cursor.execute(sql)
                print('saving')
                rs = cursor.fetchall()
                if len(rs) != 1:
                    raise Exception('error')
            finally:
                cursor.close()


def main(base_url, deep):
    url_list = []
    # å°†æ‰€æœ‰éœ€è¦çˆ¬å–çš„ url å­˜å…¥åˆ—è¡¨
    for i in range(0, deep):
        url_list.append(base_url + '&pn=' + str(50 * i))
    print('æ‰€æœ‰ç½‘é¡µå·²ä¸‹è½½åˆ°æœ¬åœ°, å¼€å§‹ç­›é€‰ä¿¡æ¯')

    conn = MySQLdb.Connect(
        host='10.0.0.112',
        port=3306,
        user='root',
        passwd='123456',
        db='spider',
        charset='utf8'
    )

    tr_save = SaveText(conn)


    # å¾ªç¯å†™å…¥æ•°æ®
    for url in url_list:
        content = get_content(url)
        # print content
        tr_save.Save2mysql(content)
    print('æ‰€æœ‰ä¿¡æ¯ä¿å­˜å®Œæ¯•')

base_url = 'http://tieba.baidu.com/f?kw=%E6%9D%83%E5%88%A9%E7%9A%84%E6%B8%B8%E6%88%8F%E7%AC%AC%E4%B8%83%E5%AD%A3&ie=utf-8&pn=0'

deep = 3

if __name__ == '__main__':
    main(base_url, deep)




